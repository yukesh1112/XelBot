XelBot - Professional Data Analytics Chatbot
=================================================

High-level one-line summary
---------------------------
XelBot is an AI-powered data analytics assistant that takes a raw CSV dataset, performs automated profiling and business analytics, lets users chat with their data in natural language, and generates professional executive-style reports.

How the system is structured
----------------------------
The project is split into four main layers:

1) Frontend UI (Streamlit)
   - File: enhanced_ui.py
   - Responsibility: Web UI that runs in the browser, handles file uploads, shows dashboards and charts, provides a chat interface, and lets the user generate reports.

2) Analytics engine
   - File: advanced_analytics.py
   - Responsibility: Pure-Python analytics layer that does data profiling, business insights, predictive analysis, and recommendations on top of pandas DataFrames.

3) Backend APIs (FastAPI)
   - Files: enhanced_backend.py and backend/app.py
   - Responsibility: REST APIs for uploading datasets, running analyses, chatting with data, and generating reports. These are a more “service” oriented back-end version of the same capabilities.

4) Launcher / Dev tooling
   - File: launch_xelbot.py
   - Responsibility: One-click script to install dependencies, start the FastAPI backend, and then start the Streamlit frontend.

Tech stack overview
-------------------
Languages & Frameworks
- Python 3: Main language for everything.
- Streamlit: Frontend web framework for building the interactive UI and dashboards (enhanced_ui.py, frontend/ui.py).
- FastAPI: Backend REST API framework for the enhanced backend (enhanced_backend.py, backend/app.py).
- Uvicorn: ASGI server used to serve the FastAPI app.

Data & Analytics Libraries
- pandas: Core data manipulation library. All dataset loading, cleaning, and feature analysis is done in pandas DataFrames.
- numpy: Numerical computing, used for numeric operations and supporting analytics.
- scipy: Statistical functions used for data-quality checks and possibly advanced analytics.
- scikit-learn: Machine-learning utilities used mainly for correlation analysis and could be extended to more advanced modeling.

Visualization
- plotly (plotly.express, plotly.graph_objects): Interactive charts in the Streamlit UI.
- matplotlib & seaborn (in frontend/ui.py, and available in requirements): Traditional plotting/heatmaps if needed.

AI / LLM Integration
- google-generativeai: Client library to talk to Google Gemini 2.0 Flash. Used in:
  - enhanced_ui.py → generate_ai_response() for chat with data in the UI.
  - enhanced_backend.py → _generate_intelligent_response() for API-based chat.
  - backend/app.py and frontend/ui.py also show similar patterns for LLM-powered responses.
- openai (in requirements): Present for optional/alternative LLM usage (not the primary path in the enhanced flow).

Reporting & BI utilities
- reportlab, jinja2, openpyxl: Listed in requirements_enhanced.txt for professional report creation and exporting (HTML, PDFs, or Excel). Current main report output is HTML via generate_executive_report in enhanced_ui.py.

HTTP & utilities
- requests, httpx: For making HTTP calls to APIs (e.g., connecting UI and backend in a microservice setup if needed).
- python-multipart: For handling file uploads in FastAPI.
- python-dateutil, pytz: Date/time utilities.

Dev tooling
- pytest, black, flake8: Testing and code-quality tools.

Detailed file-by-file explanation (what is used for what)
--------------------------------------------------------
1) enhanced_ui.py  (Streamlit frontend)

Purpose:
- This is the main modern UI the user interacts with at http://localhost:8501.
- Built with Streamlit and Plotly to feel like a professional analytics dashboard.

Key responsibilities:
- Page layout: Configures the page via st.set_page_config and global CSS.
- Sidebar:
  - File upload (CSV) using st.file_uploader.
  - Reads the CSV with pandas, handles encoding errors, basic validation (empty file check), and column name cleaning.
  - Stores the DataFrame in st.session_state.current_df.
  - “Run Complete Analysis” button which constructs AdvancedAnalytics and BusinessIntelligence objects and saves a dictionary of analysis_results in session_state.
  - Quick stats display: Data-quality score and number of generated insights.

- Main content tabs:
  1) "Chat Analysis" tab
     - Chat interface (user and bot messages) rendered with custom HTML/CSS classes (user-message, bot-message).
     - Uses generate_ai_response(question, df) to build a rich prompt with:
       - Dataset summary (shape, numeric/categorical columns, dtypes, sample data, missing values, duplicates).
       - Pre-computed business_insights from AdvancedAnalytics.
     - Calls Google Gemini via google-generativeai to get a natural-language answer.

  2) "Dashboard" tab
     - Shows dataset overview metrics: rows, columns, memory usage, data-quality.
     - Uses plotly.express to display:
       - Histogram for first numeric column.
       - Scatter plot between first two numeric columns (if available).
     - Shows four "metric-card" boxes with high-level metrics (rows, columns, size, quality) derived from analysis_results.

  3) "Insights" tab
     - Uses analysis_results['insights'], ['recommendations'], and predictive correlations from AdvancedAnalytics.
     - Presents them in three sub-tabs: Key Insights, Recommendations, Predictive Insights.
     - Uses styled HTML boxes (.insight-box, .recommendation-box) for a polished BI feel.

  4) "Reports" tab
     - When a dataset is loaded, shows a button to generate an executive HTML report.
     - Calls generate_executive_report(results), which internally recomputes a BusinessIntelligence executive_summary from the current DataFrame.
     - Executive report includes:
       - Data-quality score.
       - Dataset size and memory usage.
       - Top key insights and top recommendations.
     - The report is displayed in the UI and can be downloaded as an HTML file via st.download_button.

Important libraries used here:
- streamlit: Layout, widgets, tabs, session state.
- pandas: Reading and manipulating CSV data.
- plotly.express / plotly.graph_objects: Charts and visualizations.
- google-generativeai: Calling Gemini model for conversational responses.
- AdvancedAnalytics & BusinessIntelligence (from advanced_analytics.py): Core heavy lifting for analytics.

How to explain this to an interviewer:
- "The frontend is a Streamlit app (enhanced_ui.py). It handles CSV upload, does lightweight data validation, and stores the dataset in Streamlit session state. It then orchestrates the analytics engine (AdvancedAnalytics/BusinessIntelligence) to run a full analysis and display interactive charts. For natural language queries, it builds a structured prompt containing dataset stats and insights, sends it to Google Gemini, and shows the AI’s answer in a chat UI."

2) advanced_analytics.py  (Analytics engine)

Purpose:
- Encapsulates all non-UI analytics logic.
- Designed so both the frontend (enhanced_ui.py) and backend APIs (enhanced_backend.py) can reuse the same analytics code.

Main classes:

- AdvancedAnalytics
  - Input: a pandas DataFrame.
  - Responsibilities:
    - data_profiling():
      - Computes overview stats (rows, columns, memory, missing values, duplicates).
      - Classifies columns into numeric, categorical, datetime.
      - Builds a statistical summary for numeric and categorical data.
    - business_insights():
      - Searches for revenue/sales-like columns and calculates totals & averages.
      - Looks for customer-related columns and computes unique counts.
      - Calls _performance_metrics() to add high-level insights (e.g. conversion, engagement).
    - predictive_analysis():
      - Runs simple correlation-based analysis across numeric columns.
      - Detects strong correlations (> 0.7) and returns them as a list of variable pairs + correlation values.
    - generate_recommendations():
      - Produces human-readable business suggestions based on data patterns:
        - Clean missing data.
        - Focus on high-revenue segments.
        - Implement customer retention strategies.
        - Monitor key metrics regularly.

- BusinessIntelligence
  - Wraps AdvancedAnalytics to create an "executive_summary" dict:
    - data_overview: derived from profile['overview'].
    - key_insights: top N insights.
    - recommendations: top N recommendations.
    - data_quality_score: 0–100 score based on missing values and duplicates.

How to explain this layer:
- "The analytics engine is in advanced_analytics.py. It takes a pandas DataFrame and produces structured analytics outputs: a detailed profile, business insights, correlation-based predictive signals, and strategic recommendations. There’s also a BusinessIntelligence wrapper that converts all this into an executive summary we can show in dashboards and reports."

3) enhanced_backend.py  (Advanced FastAPI backend)

Purpose:
- Provides a production-style API for XelBot.
- Makes the project usable as a service, not just a local Streamlit app.

Key parts:
- FastAPI app configuration with CORS enabled so that any frontend (Streamlit, React, etc.) can talk to it.
- Global in-memory stores:
  - datasets: maps dataset_id → {dataframe, metadata}.
  - analysis_cache: stores profiling and full analysis results to avoid recomputation.

Important endpoints:
- GET "/" → Health/status with feature list.
- POST "/upload/" → Upload CSV, parse with pandas, store in datasets, run AdvancedAnalytics.data_profiling, cache result, and return initial overview and computed data-quality score.
- POST "/analyze/" → Run complete or quick analysis on a stored dataset using AdvancedAnalytics + BusinessIntelligence.
- POST "/chat/" → Chat with a dataset:
  - Uses Google Gemini with a context prompt built from the dataset and its insights.
  - Also generates structured data_insights and suggested follow-up questions.
- GET "/datasets/" → List uploaded datasets and analysis status.
- GET "/insights/{dataset_id}" → Return cached insights for a dataset.
- POST "/report/" → Generate a JSON-style executive report using _generate_executive_report() combining analysis_results + metadata.
- DELETE "/dataset/{dataset_id}" → Remove dataset and associated cached analysis.

Helper functions:
- _generate_intelligent_response: Builds a business consulting style prompt and calls Gemini.
- _generate_data_insights: Quick, keyword-based numeric and categorical statistics based on user question.
- _generate_follow_up_questions: Suggests next questions based on column names.
- _detect_business_domain: Guess dataset domain (Sales, Customer Analytics, etc.) from column names.
- _calculate_quality_score: Computes quality score similarly to BusinessIntelligence.

How to describe this to an interviewer:
- "The backend is a FastAPI service (enhanced_backend.py). It exposes endpoints for uploading datasets, running analyses, chatting with data, and generating an executive report object. It keeps datasets and analysis results in memory and uses the same AdvancedAnalytics/BusinessIntelligence classes as the frontend. The chat endpoints call Google Gemini with rich prompts that include shape, columns, and existing insights, so the LLM can answer as if it’s a senior data consultant."

4) backend/app.py  (Simpler FastAPI backend)

Purpose:
- A simpler or earlier version of the backend used for basic experimentation.
- Provides:
  - /upload/ endpoint to store one global dataframe.
  - /chatbot/ endpoint that uses Gemini plus simple pandas-based logic to answer typical questions (columns, rows, means, best region/product, etc.).
  - /download/ to save the processed dataset to CSV.

This file is helpful to mention if asked about API design evolution: you started with a minimal API and then built the richer enhanced_backend.py.

5) frontend/ui.py  (Original/alternate Streamlit UI)

Purpose:
- An earlier or simpler Streamlit frontend.
- Demonstrates Gemini integration and dataset-specific question answering.
- Has navigation between Home, Chatbot, and Data Insights pages.
- Uses matplotlib, seaborn, and simple visualizations.

You can say:
- "The project has an older UI (frontend/ui.py) which I used initially. The final polished version is enhanced_ui.py, which has a more professional layout, better styling, and tighter integration with the analytics engine."

6) launch_xelbot.py  (Launcher)

Purpose:
- One-click launcher to:
  - Install all enhanced dependencies from requirements_enhanced.txt.
  - Start the FastAPI backend (enhanced_backend.py) as a background process using subprocess.Popen.
  - Then start the Streamlit frontend (enhanced_ui.py).

Important concepts:
- Shows you understand how to orchestrate multiple services (API + UI) from a single Python entrypoint.
- Demonstrates familiarity with subprocesses and simple dev tooling.

7) requirements_enhanced.txt and backend/requirements.txt

Purpose:
- Capture the full dependency set for the enhanced and backend-only setups.
- Show that you know how to manage environments and versions.

How to talk about these in interviews:
- Mention that you pinned versions for compatibility (e.g., FastAPI 0.104.1, Streamlit 1.28.1, pandas 2.1.3, etc.), which is important when deploying or sharing the project.

End-to-end user flow (how everything works together)
----------------------------------------------------
1) User opens the app
   - Run `python launch_xelbot.py` or manually start `enhanced_backend.py` and `streamlit run enhanced_ui.py`.

2) User uploads a CSV in the Streamlit sidebar
   - Streamlit reads the file using pandas, validates basic properties, and stores it in session_state.current_df.

3) User clicks "Run Complete Analysis"
   - Streamlit calls AdvancedAnalytics and BusinessIntelligence.
   - analysis_results is stored with: profile, insights, predictions, recommendations, executive_summary.

4) User explores the Dashboard
   - Sees key summary metrics and automatic visualizations built with Plotly.

5) User chats with XelBot
   - Their question and the current DataFrame are passed to generate_ai_response.
   - A structured prompt containing dataset stats, sample data, and top insights is sent to Gemini.
   - Gemini returns a natural-language, business-focused answer.

6) User checks Insights tab
   - Key Insights and Recommendations from analysis_results are presented in well-styled sections and tabs.

7) User generates an Executive Report
   - Reports tab calls generate_executive_report.
   - This function recomputes an executive summary from the current DataFrame via BusinessIntelligence and builds an HTML report.
   - User can download the report as an HTML file.

How to pitch the project in an interview
---------------------------------------
Short pitch (30–60 seconds):
- "XelBot is an AI-powered data analytics chatbot. You upload a CSV file, and the system automatically profiles the data, computes key business insights, and lets you ask free-form questions about your data in natural language. The frontend is built in Streamlit with Plotly for interactive dashboards. The heavy analytics logic is encapsulated in a separate module that uses pandas, NumPy, SciPy, and scikit-learn. For conversational AI, I integrated Google’s Gemini model using the google-generativeai SDK with carefully engineered prompts that include dataset context. There is also a FastAPI backend that exposes these capabilities as REST APIs, plus a one-click launcher that starts both the backend and frontend."

Slightly deeper pitch (when they ask "tell me about the architecture"):
- "Architecturally, I separated concerns into a Streamlit UI layer, a reusable analytics engine, and a FastAPI service layer. The UI handles user interaction, visualization, and chat history. The analytics engine provides data profiling, business insights, correlation-based predictive analysis, and recommendations on any pandas DataFrame. The FastAPI backend exposes upload/analyze/chat/report endpoints so the same analytics logic can be used by other clients as well. Google Gemini is used as a co-pilot for interpretation and explanation: it receives a rich prompt with dataset statistics and high-level insights, and returns human-readable business recommendations. Finally, I added an executive report generator that assembles the key metrics, insights, and recommendations into a nicely formatted HTML report that’s ready to share."

You can adapt and shorten any of these sections depending on how deep the interviewer wants to go.
